{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Search Engine - Web.ipynb","provenance":[],"authorship_tag":"ABX9TyNm7OZXbU2RChO3nxbkG9Ga"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"YcHW86B1PSoX","executionInfo":{"status":"ok","timestamp":1628066106663,"user_tz":-330,"elapsed":10055,"user":{"displayName":"Prabu M Computer Science","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgcP7tC5ALkzcly4Bj28hCo--RVewJJ1A1NdEF8-g=s64","userId":"17748823969428159160"}}},"source":["import requests\n","from bs4 import BeautifulSoup\n","# Make a request to the website\n","r = requests.get('https://bola.kompas.com/')\n","# Create an object to parse the HTML format\n","soup = BeautifulSoup(r.content, 'html.parser')\n","# Retrieve all popular news links (Fig. 1)\n","link = []\n","for i in soup.find('div', {'class':'most__wrap'}).find_all('a'):\n","    i['href'] = i['href'] + '?page=all'\n","    link.append(i['href'])\n","# For each link, we retrieve paragraphs from it, combine each paragraph as one string, and save it to documents (Fig. 2)\n","documents = []\n","for i in link:\n","    # Make a request to the link\n","    r = requests.get(i)\n","  \n","    # Initialize BeautifulSoup object to parse the content \n","    soup = BeautifulSoup(r.content, 'html.parser')\n","  \n","    # Retrieve all paragraphs and combine it as one\n","    sen = []\n","    for i in soup.find('div', {'class':'read__content'}).find_all('p'):\n","        sen.append(i.text)\n","  \n","    # Add the combined paragraphs to documents\n","    documents.append(' '.join(sen))"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"VR0DxDLTPbpM","executionInfo":{"status":"ok","timestamp":1628066128742,"user_tz":-330,"elapsed":514,"user":{"displayName":"Prabu M Computer Science","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgcP7tC5ALkzcly4Bj28hCo--RVewJJ1A1NdEF8-g=s64","userId":"17748823969428159160"}}},"source":["import re\n","import string\n","documents_clean = []\n","for d in documents:\n","    # Remove Unicode\n","    document_test = re.sub(r'[^\\x00-\\x7F]+', ' ', d)\n","    # Remove Mentions\n","    document_test = re.sub(r'@\\w+', '', document_test)\n","    # Lowercase the document\n","    document_test = document_test.lower()\n","    # Remove punctuations\n","    document_test = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', document_test)\n","    # Lowercase the numbers\n","    document_test = re.sub(r'[0-9]', '', document_test)\n","    # Remove the doubled space\n","    document_test = re.sub(r'\\s{2,}', ' ', document_test)\n","    documents_clean.append(document_test)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8cznKpcPk1x"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","import pandas as pd\n","# Instantiate a TfidfVectorizer object\n","vectorizer = TfidfVectorizer()\n","# It fits the data and transform it as a vector\n","X = vectorizer.fit_transform(documents_clean)\n","# Convert the X as transposed matrix\n","X = X.T.toarray()\n","# Create a DataFrame and set the vocabulary as the index\n","df = pd.DataFrame(X, index=vectorizer.get_feature_names())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ERhuC6HTP2uZ","executionInfo":{"status":"ok","timestamp":1628066455672,"user_tz":-330,"elapsed":5168,"user":{"displayName":"Prabu M Computer Science","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgcP7tC5ALkzcly4Bj28hCo--RVewJJ1A1NdEF8-g=s64","userId":"17748823969428159160"}},"outputId":"5bf9ebf6-f1b9-4e00-b395-28bd237c34ab"},"source":["import numpy as np\n","def get_similar_articles(q, df):\n","  print(\"query:\", q)\n","  print(\"Here are the articles with the highest  similarity values: \")\n","  # Convert the query become a vector\n","  q = [q]\n","  q_vec = vectorizer.transform(q).toarray().reshape(df.shape[0],)\n","  sim = {}\n","  # Calculate the similarity\n","  for i in range(10):\n","    sim[i] = np.dot(df.loc[:, i].values, q_vec) / np.linalg.norm(df.loc[:, i]) * np.linalg.norm(q_vec)\n","  \n","  # Sort the values \n","  sim_sorted = sorted(sim.items(), key=lambda x: x[1], reverse=True)\n","  # Print the articles and their similarity values\n","  for k, v in sim_sorted:\n","    if v != 0.0:\n","      print(\"Similaritas:\", v)\n","      print(documents_clean[k])\n","      print()\n","# Add The Query\n","q1 = input()\n","# Call the function\n","get_similar_articles(q1, df)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["barcelona\n","query: barcelona\n","Here are the articles with the highest  similarity values: \n","Similaritas: 0.03950152928836981\n","kompas com china berhasil mempertahankan singgasana perolehan medali hingga hari ke perhelatan olimpiade tokyo atau sampai selasa malam wib china menempati posisi pertama klasemen medali olimpiade tokyo dengan raihan emas perak dan perunggu di posisi kedua terdapat amerika serikat as yang sudah mengoleksi emas perak dan perunggu jumlah total perolehan medali as sebenarnya lebih banyak daripada china yakni berbanding akan tetapi china berhak menempati puncak klasemen medali olimpiade tokyo karena memiliki kepingan emas lebih banyak baca juga masuk besar klasemen olimpiade tokyo indonesia sementara penuhi target adapun di peringkat ketiga ada tuan rumah jepang dengan raihan medali emas perak dan perunggu atau total medali dapatkan informasi inspirasi dan insight di email kamu daftarkan email sementara itu indonesia kini menempati posisi ke dengan koleksi satu medali emas satu perak dan tiga perunggu atau total lima medali jumlah perolehan indonesia identik atau sama dengan yang diraih oleh austria dan serbia yakni satu medali emas satu perak dan tiga perunggu medali seperti dikutip di situs resmi olimpiade medali emas indonesia dipersembahkan dari cabor bulu tangkis sektor ganda putri atas nama greysia polii apriyani rahayu selain itu bulu tangkis pun menyumbang satu medali perunggu yang dipersembahkan tunggal putra anthony sinisuka ginting baca juga update klasemen olimpiade tokyo anthony ginting tambah medali indonesia satu medali perak dan dua medali perunggu indonesia lainnya lahir dari cabor angkat besi eko yuli irawan menjadi atlet indonesia yang berhasil meraih medali perak ketika turun di kelas kg putra adapun windy cantika aisah kg putri dan rahmat erwin abdullah kg putra menjadi lifter indonesia yang berhasil membawa pulang medali perunggu dari olimpiade tokyo kontingen indonesia sudah dipastikan tidak bisa menambah perolehan medalinya meskipun olimpiade tokyo masih akan berlangsung sampai agustus sebab atlet yang menjadi wakil indonesia di olimpiade tokyo sudah menyelesaikan pertandingan mereka baca juga lifter nurul akmal tutup perjuangan indonesia di olimpiade tokyo berikut klasemen medali olimpiade tokyo hingga hari ke selasa klasemen lengkap olimpiade tokyo dapat diklik pada link berikut klasemen medali olimpiade tokyo \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pizZRJtTRPVD"},"source":[""],"execution_count":null,"outputs":[]}]}